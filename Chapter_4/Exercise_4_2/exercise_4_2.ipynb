{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0000000001\n",
    "max_num_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_policy_evaluation(init_state_values, transitions):\n",
    "    state_values = init_state_values # Index 0 is the terminal state\n",
    "    for i in range(max_num_iterations):\n",
    "        for j in range(1, len(state_values)):\n",
    "            previous_state_values = state_values.copy()\n",
    "            state_values[j] = -1 + 0.25 * np.sum(state_values[transitions[j]])\n",
    "        delta = np.linalg.norm(previous_state_values - state_values)\n",
    "        if delta < threshold:\n",
    "            break\n",
    "    print(\"num iterations:\", i + 1)\n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating results from the original example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num iterations: 265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0., -14., -20., -22., -14., -18., -20., -20., -20., -20., -18.,\n",
       "       -14., -22., -20., -14.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What state will the agent get to after selecting either {up, down, right, left} from state i\n",
    "transitions = [\n",
    "    [0, 0, 0, 0], # The agent is stuck in the terminal state\n",
    "    [1, 5, 2, 0],\n",
    "    [2, 6, 3, 1],\n",
    "    [3, 7, 3, 2],\n",
    "    [0, 8, 5, 4],\n",
    "    [1, 9, 6, 4],\n",
    "    [2, 10, 5, 7],\n",
    "    [3, 11, 7, 6],\n",
    "    [4, 12, 9, 8],\n",
    "    [5, 13, 10, 8],\n",
    "    [6, 14, 11, 9],\n",
    "    [7, 0, 11, 10],\n",
    "    [8, 12, 13, 12],\n",
    "    [9, 13, 14, 12],\n",
    "    [10, 14, 0, 13]\n",
    "]\n",
    "iterative_policy_evaluation(np.zeros(15), transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding state 15, but not changing any transitions from the other states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num iterations: 270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0., -14., -20., -22., -14., -18., -20., -20., -20., -20., -18.,\n",
       "       -14., -22., -20., -14., -20.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transitions = [\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 5, 2, 0],\n",
    "    [2, 6, 3, 1],\n",
    "    [3, 7, 3, 2],\n",
    "    [0, 8, 5, 4],\n",
    "    [1, 9, 6, 4],\n",
    "    [2, 10, 5, 7],\n",
    "    [3, 11, 7, 6],\n",
    "    [4, 12, 9, 8],\n",
    "    [5, 13, 10, 8],\n",
    "    [6, 14, 11, 9],\n",
    "    [7, 0, 11, 10],\n",
    "    [8, 12, 13, 12],\n",
    "    [9, 13, 14, 12],\n",
    "    [10, 14, 0, 13],\n",
    "    [13, 15, 14, 12]\n",
    "]\n",
    "iterative_policy_evaluation(np.zeros(16), new_transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding state 15 and changing the transitions for state 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num iterations: 268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0., -14., -20., -22., -14., -18., -20., -20., -20., -20., -18.,\n",
       "       -14., -22., -20., -14., -20.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transitions_2 = [\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 5, 2, 0],\n",
    "    [2, 6, 3, 1],\n",
    "    [3, 7, 3, 2],\n",
    "    [0, 8, 5, 4],\n",
    "    [1, 9, 6, 4],\n",
    "    [2, 10, 5, 7],\n",
    "    [3, 11, 7, 6],\n",
    "    [4, 12, 9, 8],\n",
    "    [5, 13, 10, 8],\n",
    "    [6, 14, 11, 9],\n",
    "    [7, 0, 11, 10],\n",
    "    [8, 12, 13, 12],\n",
    "    [9, 15, 14, 12],\n",
    "    [10, 14, 0, 13],\n",
    "    [13, 15, 14, 12]\n",
    "]\n",
    "iterative_policy_evaluation(np.zeros(16), new_transitions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f26179ee78db2aa81e6834ad6dc21cf32f3392ab3632a5346cf30ea04832c43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
