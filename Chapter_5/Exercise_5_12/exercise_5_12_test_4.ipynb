{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(7)\n",
    "from exercise_5_12 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "starting_line, finishing_line, track = get_tiny_map()\n",
    "plot_map(starting_line, finishing_line, track, (6, 6), (5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "policy, b, Q, C = initialize_learning_off_pol(starting_line, track)\n",
    "for ep in range(num_episodes):\n",
    "    states, actions, rewards = generate_episode(starting_line, finishing_line, track, b, noise=0.0)\n",
    "    policy, Q, C = learn_from_episode_off_pol(policy, b, Q, C, states, actions, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 1.0, (1, 0): 0.0, (1, 1): 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy[(3, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[(3, 0, 0, 0), (0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[(3, 0, 0, 0), (1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy, b, Q, C = initialize_learning_off_pol(starting_line, track)\n",
    "G = 0\n",
    "W = 1\n",
    "for t in range(len(states) - 1, -1, -1):\n",
    "    print(t)\n",
    "    s = states[t]\n",
    "    a = actions[t]\n",
    "    G = 1 * G + rewards[t]\n",
    "    C[(s, a)] += W\n",
    "    Q[(s, a)] += (W / C[(s, a)]) * (G - Q[(s, a)])\n",
    "    \n",
    "    # Argmax over a, break ties by favoring the last selected action by b,\n",
    "    # then by the deterministic ordering of get_greedy_action.\n",
    "    # If not \"favoring the last selected action by b\", and simply relying on\n",
    "    # the ordering of get_greedy_action, the algorithm can easily get stuck,\n",
    "    # even though get_greedy_action provides consistent ordering.\n",
    "    #greedy_action = get_greedy_action(Q, s)\n",
    "    #if Q[(s, a)] == Q[(s, greedy_action)]:\n",
    "    #    policy[s] = get_eps_greedy_probabilities(s, a)\n",
    "    #else:\n",
    "    #    policy[s] = get_eps_greedy_probabilities(s, greedy_action)\n",
    "    policy[s] = get_eps_greedy_probabilities(s, get_greedy_action(Q, s))\n",
    "    \n",
    "    if list(policy[s].keys())[list(policy[s].values()).index(1)] != a:\n",
    "        print(\"break\")\n",
    "        break\n",
    "    W = W * (1 / b[s][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(policy[s].keys())[list(policy[s].values()).index(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f26179ee78db2aa81e6834ad6dc21cf32f3392ab3632a5346cf30ea04832c43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
